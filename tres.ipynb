{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 3.7959\n",
      "Epoch [20/100], Loss: 3.6642\n",
      "Epoch [30/100], Loss: 3.5541\n",
      "Epoch [40/100], Loss: 3.4475\n",
      "Epoch [50/100], Loss: 3.3437\n",
      "Epoch [60/100], Loss: 3.2407\n",
      "Epoch [70/100], Loss: 3.1375\n",
      "Epoch [80/100], Loss: 3.0259\n",
      "Epoch [90/100], Loss: 2.9100\n",
      "Epoch [100/100], Loss: 2.7901\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "carpeta = 'CSVS'  # Asegúrate de reemplazar 'CSVS' con la ruta real de la carpeta\n",
    "\n",
    "# Obtener la lista de archivos CSV en la carpeta que empiezan por \"temp\"\n",
    "archivos_csv = [os.path.join(carpeta, archivo) for archivo in os.listdir(carpeta) if archivo.startswith('temp') and archivo.endswith('.csv')]\n",
    "\n",
    "# Leer todos los archivos CSV y combinarlos en un solo DataFrame\n",
    "dfs = []\n",
    "for archivo_csv in archivos_csv:\n",
    "    df = pd.read_csv(archivo_csv)\n",
    "    dfs.append(df)\n",
    "\n",
    "df_combined = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Convertir la columna \"fase\" a minúsculas y capitalizar la primera letra\n",
    "df_combined['fase'] = df_combined['fase'].astype(str).str.lower().str.capitalize()\n",
    "\n",
    "# Codificación de variables categóricas\n",
    "label_encoder = LabelEncoder()\n",
    "df['equipo_local'] = label_encoder.fit_transform(df['equipo_local'])\n",
    "df['equipo_visitante'] = label_encoder.transform(df['equipo_visitante'])\n",
    "df['fase'] = label_encoder.fit_transform(df['fase'])\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define el modelo\n",
    "class PredictorModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(PredictorModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# Tamaño de las capas de entrada, oculta y salida\n",
    "input_size = 3\n",
    "hidden_size = 5\n",
    "output_size = 2  # Salida para goles_equipo_local y goles_equipo_visitante\n",
    "\n",
    "# Instancia del modelo\n",
    "model = PredictorModel(input_size, hidden_size, output_size)\n",
    "\n",
    "# Función de pérdida y optimizador\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "num_epochs = 100  # Puedes ajustar el número de épocas\n",
    "for epoch in range(num_epochs):\n",
    "    inputs = torch.tensor(train_data[['fase', 'equipo_local', 'equipo_visitante']].values, dtype=torch.float32)\n",
    "    labels = torch.tensor(train_data[['goles_equipo_local', 'goles_equipo_visitante']].values, dtype=torch.float32)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "torch.save(model.state_dict(), 'modelo_entrenado3.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_encode.py:225\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_map_to_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_encode.py:165\u001b[0m, in \u001b[0;36m_map_to_integer\u001b[1;34m(values, uniques)\u001b[0m\n\u001b[0;32m    164\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[1;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([table[v] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[1;32mc:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_encode.py:165\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    164\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[1;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mtable\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[1;32mc:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_encode.py:159\u001b[0m, in \u001b[0;36m_nandict.__missing__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnan_value\n\u001b[1;32m--> 159\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Iterar sobre cada fila del DataFrame de partidos\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m partidos_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# Obtener los datos de entrada para hacer la predicción\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     fase \u001b[38;5;241m=\u001b[39m \u001b[43mlabel_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfase\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Transformar la fase a su valor codificado\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     equipo_local \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequipo_local\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     27\u001b[0m     equipo_visitante \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequipo_visitante\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:137\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_encode.py:227\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 227\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_unknown:\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: 2"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Cargar el modelo entrenado\n",
    "model = PredictorModel(input_size, hidden_size, output_size)\n",
    "model.load_state_dict(torch.load(\"modelo_entrenado3.pth\"))  # Asegúrate de reemplazar \"ruta_del_modelo_entrenado.pth\" con la ruta real\n",
    "\n",
    "# Leer el archivo CSV con los partidos\n",
    "partidos_df = pd.read_csv(\"Eliminatoria actual/cuartos.csv\")  # Asegúrate de reemplazar \"ruta_del_archivo_csv.csv\" con la ruta real\n",
    "# Convertir la columna \"fase\" a minúsculas y capitalizar la primera letra\n",
    "partidos_df['fase'] = partidos_df['fase'].str.lower().str.capitalize()\n",
    "\n",
    "# Crea un diccionario para mapear las etapas a valores numéricos\n",
    "etapas_dict = {'Grupos': 0, 'Octavos': 1, 'Cuartos': 2, 'Semis': 3, 'Final': 4}\n",
    "\n",
    "# Reemplaza las etiquetas de las etapas con valores numéricos\n",
    "partidos_df['fase'] = partidos_df['fase'].map(etapas_dict)\n",
    "\n",
    "# Crear un DataFrame para almacenar las predicciones completas de goles\n",
    "predicciones_df = pd.DataFrame(columns=[\"fase\", \"equipo_local\", \"goles_equipo_local\", \"equipo_visitante\", \"goles_equipo_visitante\"])\n",
    "\n",
    "# Iterar sobre cada fila del DataFrame de partidos\n",
    "for index, row in partidos_df.iterrows():\n",
    "    # Obtener los datos de entrada para hacer la predicción\n",
    "    fase = label_encoder.transform([row[\"fase\"]])[0]  # Transformar la fase a su valor codificado\n",
    "    equipo_local = row[\"equipo_local\"]\n",
    "    equipo_visitante = row[\"equipo_visitante\"]\n",
    "    datos_prediccion = torch.tensor([[fase, equipo_local, equipo_visitante]], dtype=torch.float32)\n",
    "    \n",
    "    # Realizar la predicción utilizando el modelo\n",
    "    predicciones = model(datos_prediccion).detach().numpy().round().astype(int)\n",
    "    \n",
    "    # Crear un nuevo DataFrame con la predicción completa para este partido\n",
    "    nueva_fila = {\n",
    "        \"fase\": row[\"fase\"],\n",
    "        \"equipo_local\": row[\"equipo_local\"],\n",
    "        \"goles_equipo_local\": predicciones[0][0],\n",
    "        \"equipo_visitante\": row[\"equipo_visitante\"],\n",
    "        \"goles_equipo_visitante\": predicciones[0][1]\n",
    "    }\n",
    "    predicciones_df = predicciones_df.append(nueva_fila, ignore_index=True)\n",
    "\n",
    "\n",
    "# Guardar el DataFrame con las predicciones completas en un nuevo archivo CSV\n",
    "predicciones_df.to_csv(\"predicciones_completas.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: nan\n",
      "Epoch [20/100], Loss: nan\n",
      "Epoch [30/100], Loss: nan\n",
      "Epoch [40/100], Loss: nan\n",
      "Epoch [50/100], Loss: nan\n",
      "Epoch [60/100], Loss: nan\n",
      "Epoch [70/100], Loss: nan\n",
      "Epoch [80/100], Loss: nan\n",
      "Epoch [90/100], Loss: nan\n",
      "Epoch [100/100], Loss: nan\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 'Cuartos'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_encode.py:225\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_map_to_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_encode.py:165\u001b[0m, in \u001b[0;36m_map_to_integer\u001b[1;34m(values, uniques)\u001b[0m\n\u001b[0;32m    164\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[1;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([table[v] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[1;32mc:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_encode.py:165\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    164\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[1;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mtable\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[1;32mc:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_encode.py:159\u001b[0m, in \u001b[0;36m_nandict.__missing__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnan_value\n\u001b[1;32m--> 159\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Cuartos'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 88\u001b[0m\n\u001b[0;32m     85\u001b[0m partidos_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfase\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m partidos_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfase\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcapitalize()\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# Reemplazar las etiquetas de las etapas con valores numéricos\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m partidos_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfase\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mlabel_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartidos_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfase\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Crear un DataFrame para almacenar las predicciones completas de goles\u001b[39;00m\n\u001b[0;32m     91\u001b[0m predicciones_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfase\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequipo_local\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoles_equipo_local\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequipo_visitante\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoles_equipo_visitante\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:137\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_encode.py:227\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 227\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_unknown:\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: 'Cuartos'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "# Definir el modelo PredictorModel\n",
    "class PredictorModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(PredictorModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# Ruta de la carpeta que contiene los archivos CSV\n",
    "carpeta = 'CSVS'\n",
    "\n",
    "# Obtener la lista de archivos CSV en la carpeta que empiezan por \"temp\"\n",
    "archivos_csv = [os.path.join(carpeta, archivo) for archivo in os.listdir(carpeta) if archivo.startswith('temp') and archivo.endswith('.csv')]\n",
    "\n",
    "# Leer todos los archivos CSV y combinarlos en un solo DataFrame\n",
    "dfs = []\n",
    "for archivo_csv in archivos_csv:\n",
    "    df = pd.read_csv(archivo_csv)\n",
    "    dfs.append(df)\n",
    "\n",
    "df_combined = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Convertir la columna \"fase\" a minúsculas y capitalizar la primera letra\n",
    "df_combined['fase'] = df_combined['fase'].str.lower().str.capitalize()\n",
    "\n",
    "# Codificación de variables categóricas\n",
    "label_encoder = LabelEncoder()\n",
    "df_combined['fase'] = label_encoder.fit_transform(df_combined['fase'])\n",
    "df_combined['equipo_local'] = label_encoder.fit_transform(df_combined['equipo_local'])\n",
    "df_combined['equipo_visitante'] = label_encoder.fit_transform(df_combined['equipo_visitante'])\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "train_data, test_data = train_test_split(df_combined, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tamaño de las capas de entrada, oculta y salida\n",
    "input_size = 3\n",
    "hidden_size = 5\n",
    "output_size = 2\n",
    "\n",
    "# Instancia del modelo PredictorModel\n",
    "model = PredictorModel(input_size, hidden_size, output_size)\n",
    "\n",
    "# Función de pérdida y optimizador\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    inputs = torch.tensor(train_data[['fase', 'equipo_local', 'equipo_visitante']].values, dtype=torch.float32)\n",
    "    labels = torch.tensor(train_data[['goles_equipo_local', 'goles_equipo_visitante']].values, dtype=torch.float32)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "torch.save(model.state_dict(), 'modelo_entrenado.pth')\n",
    "\n",
    "# Cargar el modelo entrenado\n",
    "model = PredictorModel(input_size, hidden_size, output_size)\n",
    "model.load_state_dict(torch.load(\"modelo_entrenado.pth\"))\n",
    "\n",
    "# Leer el archivo CSV con los partidos\n",
    "partidos_df = pd.read_csv(\"Eliminatoria actual/cuartos.csv\")\n",
    "\n",
    "# Convertir la columna \"fase\" a minúsculas y capitalizar la primera letra\n",
    "partidos_df['fase'] = partidos_df['fase'].str.lower().str.capitalize()\n",
    "\n",
    "# Reemplazar las etiquetas de las etapas con valores numéricos\n",
    "partidos_df['fase'] = label_encoder.transform(partidos_df['fase'])\n",
    "\n",
    "# Crear un DataFrame para almacenar las predicciones completas de goles\n",
    "predicciones_df = pd.DataFrame(columns=[\"fase\", \"equipo_local\", \"goles_equipo_local\", \"equipo_visitante\", \"goles_equipo_visitante\"])\n",
    "\n",
    "# Iterar sobre cada fila del DataFrame de partidos\n",
    "for index, row in partidos_df.iterrows():\n",
    "    # Obtener los datos de entrada para hacer la predicción\n",
    "    fase = row[\"fase\"]\n",
    "    equipo_local = row[\"equipo_local\"]\n",
    "    equipo_visitante = row[\"equipo_visitante\"]\n",
    "    datos_prediccion = torch.tensor([[fase, equipo_local, equipo_visitante]], dtype=torch.float32)\n",
    "    \n",
    "    # Realizar la predicción utilizando el modelo\n",
    "    predicciones = model(datos_prediccion).detach().numpy().round().astype(int)\n",
    "    \n",
    "    # Crear un nuevo DataFrame con la predicción completa para este partido\n",
    "    nueva_fila = {\n",
    "        \"fase\": row[\"fase\"],\n",
    "        \"equipo_local\": row[\"equipo_local\"],\n",
    "        \"goles_equipo_local\": predicciones[0][0],\n",
    "        \"equipo_visitante\": row[\"equipo_visitante\"],\n",
    "        \"goles_equipo_visitante\": predicciones[0][1]\n",
    "    }\n",
    "    predicciones_df = predicciones_df.append(nueva_fila, ignore_index=True)\n",
    "\n",
    "# Guardar el DataFrame con las predicciones completas en un nuevo archivo CSV\n",
    "predicciones_df.to_csv(\"predicciones_completas.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
