{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 8.6076\n",
      "Epoch [20/100], Loss: 7.0519\n",
      "Epoch [30/100], Loss: 5.7517\n",
      "Epoch [40/100], Loss: 4.6327\n",
      "Epoch [50/100], Loss: 3.5938\n",
      "Epoch [60/100], Loss: 2.8037\n",
      "Epoch [70/100], Loss: 2.3124\n",
      "Epoch [80/100], Loss: 2.0517\n",
      "Epoch [90/100], Loss: 1.9382\n",
      "Epoch [100/100], Loss: 1.8952\n",
      "    goles_equipo_local  goles_equipo_visitante\n",
      "0             2.336351                1.877128\n",
      "1             0.862828                1.067372\n",
      "2             2.309014                1.187963\n",
      "3             1.289278                1.753771\n",
      "4             2.225221                1.935949\n",
      "5             1.295551                1.594087\n",
      "6             1.833130                2.221665\n",
      "7             1.385616                0.686417\n",
      "8             2.028053                1.414857\n",
      "9             1.538126                1.882661\n",
      "10            1.143789                0.840477\n",
      "11            1.205948                0.455777\n",
      "12            0.966937                0.725601\n",
      "13            1.359776                0.882518\n",
      "14            1.406681                1.535266\n",
      "15            2.304238                2.232912\n",
      "16            1.701685                1.874271\n",
      "17            2.257334                1.580165\n",
      "18            2.080481                1.465288\n",
      "19            2.172793                1.885518\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Lee el CSV\n",
    "df = pd.read_csv('CSVS/temp2023_24.csv')\n",
    "\n",
    "# Codificación de variables categóricas\n",
    "label_encoder = LabelEncoder()\n",
    "df['equipo_local'] = label_encoder.fit_transform(df['equipo_local'])\n",
    "df['equipo_visitante'] = label_encoder.transform(df['equipo_visitante'])\n",
    "df['fase'] = label_encoder.fit_transform(df['fase'])\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PredictorModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(PredictorModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "input_size = 3\n",
    "hidden_size = 5\n",
    "output_size = 2  # Salida para goles_equipo_local y goles_equipo_visitante\n",
    "\n",
    "model = PredictorModel(input_size, hidden_size, output_size)\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()  # Puedes ajustar la función de pérdida según tu problema\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Puedes ajustar la tasa de aprendizaje\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "num_epochs = 100  # Puedes ajustar el número de épocas\n",
    "for epoch in range(num_epochs):\n",
    "    inputs = torch.tensor(train_data[['fase', 'equipo_local', 'equipo_visitante']].values, dtype=torch.float32)\n",
    "    labels = torch.tensor(train_data[['goles_equipo_local', 'goles_equipo_visitante']].values, dtype=torch.float32)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "# Predicciones en el conjunto de prueba\n",
    "with torch.no_grad():\n",
    "    test_inputs = torch.tensor(test_data[['fase', 'equipo_local', 'equipo_visitante']].values, dtype=torch.float32)\n",
    "    predictions = model(test_inputs).numpy()\n",
    "\n",
    "# Convierte las predicciones a un DataFrame de pandas y descodifica las variables categóricas si es necesario\n",
    "predictions_df = pd.DataFrame(predictions, columns=['goles_equipo_local', 'goles_equipo_visitante'])\n",
    "\n",
    "print(predictions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disminuye pero es muy alta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 3.6797\n",
      "Epoch [20/100], Loss: 3.5700\n",
      "Epoch [30/100], Loss: 3.4718\n",
      "Epoch [40/100], Loss: 3.3835\n",
      "Epoch [50/100], Loss: 3.2991\n",
      "Epoch [60/100], Loss: 3.2096\n",
      "Epoch [70/100], Loss: 3.1205\n",
      "Epoch [80/100], Loss: 3.0329\n",
      "Epoch [90/100], Loss: 2.9400\n",
      "Epoch [100/100], Loss: 2.8478\n",
      "    goles_equipo_local  goles_equipo_visitante\n",
      "0                    0                       0\n",
      "1                    1                       0\n",
      "2                    1                       1\n",
      "3                    0                       0\n",
      "4                    0                       0\n",
      "5                    0                       0\n",
      "6                    0                       0\n",
      "7                    1                       2\n",
      "8                    1                       1\n",
      "9                    0                       0\n",
      "10                   1                       1\n",
      "11                   1                       2\n",
      "12                   1                       1\n",
      "13                   1                       1\n",
      "14                   0                       0\n",
      "15                   0                       0\n",
      "16                   0                       0\n",
      "17                   1                       0\n",
      "18                   1                       1\n",
      "19                   0                       0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Lee el CSV\n",
    "df = pd.read_csv('CSVS/temp2023_24.csv')\n",
    "\n",
    "# Codificación de variables categóricas\n",
    "label_encoder = LabelEncoder()\n",
    "df['equipo_local'] = label_encoder.fit_transform(df['equipo_local'])\n",
    "df['equipo_visitante'] = label_encoder.transform(df['equipo_visitante'])\n",
    "df['fase'] = label_encoder.fit_transform(df['fase'])\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PredictorModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(PredictorModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "input_size = 3\n",
    "hidden_size = 5\n",
    "output_size = 2  # Salida para goles_equipo_local y goles_equipo_visitante\n",
    "\n",
    "model = PredictorModel(input_size, hidden_size, output_size)\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()  # Puedes ajustar la función de pérdida según tu problema\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Puedes ajustar la tasa de aprendizaje\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "num_epochs = 100  # Puedes ajustar el número de épocas\n",
    "for epoch in range(num_epochs):\n",
    "    inputs = torch.tensor(train_data[['fase', 'equipo_local', 'equipo_visitante']].values, dtype=torch.float32)\n",
    "    labels = torch.tensor(train_data[['goles_equipo_local', 'goles_equipo_visitante']].values, dtype=torch.float32)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "# Predicciones en el conjunto de prueba\n",
    "with torch.no_grad():\n",
    "    test_inputs = torch.tensor(test_data[['fase', 'equipo_local', 'equipo_visitante']].values, dtype=torch.float32)\n",
    "    predictions = model(test_inputs).numpy()\n",
    "\n",
    "# Redondea las predicciones a números enteros\n",
    "predictions = predictions.round().astype(int)\n",
    "\n",
    "# Convierte las predicciones a un DataFrame de pandas\n",
    "predictions_df = pd.DataFrame(predictions, columns=['goles_equipo_local', 'goles_equipo_visitante'])\n",
    "\n",
    "print(predictions_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m archivos_csv \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(carpeta, archivo) \u001b[38;5;28;01mfor\u001b[39;00m archivo \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(carpeta) \u001b[38;5;28;01mif\u001b[39;00m archivo\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemp\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m archivo\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Convertir la columna \"fase\" a minúsculas y capitalizar la primera letra\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfase\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfase\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcapitalize()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Crea un diccionario para mapear las etapas a valores numéricos\u001b[39;00m\n\u001b[0;32m     20\u001b[0m etapas_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGrupos\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOctavos\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCuartos\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSemis\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinal\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m4\u001b[39m}\n",
      "File \u001b[1;32mc:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5569\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5570\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5571\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5572\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5573\u001b[0m ):\n\u001b[0;32m   5574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\accessor.py:182\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 182\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32mc:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:177\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[1;32m--> 177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m is_categorical_dtype(data\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[1;32mc:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:231\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    228\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[1;32m--> 231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "# Lee el CSV de datos de entrenamiento\n",
    "# Ruta de la carpeta que contiene los archivos CSV\n",
    "carpeta = 'CSVS'  # Asegúrate de reemplazar 'CSVS' con la ruta real de la carpeta\n",
    "\n",
    "# Obtener la lista de archivos CSV en la carpeta que empiezan por \"temp\"\n",
    "archivos_csv = [os.path.join(carpeta, archivo) for archivo in os.listdir(carpeta) if archivo.startswith('temp') and archivo.endswith('.csv')]\n",
    "\n",
    "# Convertir la columna \"fase\" a minúsculas y capitalizar la primera letra\n",
    "df['fase'] = df['fase'].str.lower().str.capitalize()\n",
    "\n",
    "# Crea un diccionario para mapear las etapas a valores numéricos\n",
    "etapas_dict = {'Grupos': 0, 'Octavos': 1, 'Cuartos': 2, 'Semis': 3, 'Final': 4}\n",
    "\n",
    "# Reemplaza las etiquetas de las etapas con valores numéricos\n",
    "df['fase'] = df['fase'].map(etapas_dict)\n",
    "\n",
    "# Codificación de variables categóricas\n",
    "label_encoder = LabelEncoder()\n",
    "df['equipo_local'] = label_encoder.fit_transform(df['equipo_local'])\n",
    "df['equipo_visitante'] = label_encoder.transform(df['equipo_visitante'])\n",
    "df['fase'] = label_encoder.fit_transform(df['fase'])\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define el modelo\n",
    "class PredictorModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(PredictorModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# Tamaño de las capas de entrada, oculta y salida\n",
    "input_size = 3\n",
    "hidden_size = 5\n",
    "output_size = 2  # Salida para goles_equipo_local y goles_equipo_visitante\n",
    "\n",
    "# Instancia del modelo\n",
    "model = PredictorModel(input_size, hidden_size, output_size)\n",
    "\n",
    "# Función de pérdida y optimizador\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "num_epochs = 100  # Puedes ajustar el número de épocas\n",
    "for epoch in range(num_epochs):\n",
    "    inputs = torch.tensor(train_data[['fase', 'equipo_local', 'equipo_visitante']].values, dtype=torch.float32)\n",
    "    labels = torch.tensor(train_data[['goles_equipo_local', 'goles_equipo_visitante']].values, dtype=torch.float32)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "torch.save(model.state_dict(), 'modelo_entrenado2.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: [2.0]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Iterar sobre cada fila del DataFrame de partidos\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m partidos_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# Obtener los datos de entrada para hacer la predicción\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     fase \u001b[38;5;241m=\u001b[39m \u001b[43mlabel_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfase\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Transformar la fase a su valor codificado\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     equipo_local \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequipo_local\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     23\u001b[0m     equipo_visitante \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequipo_visitante\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:137\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_encode.py:232\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    230\u001b[0m     diff \u001b[38;5;241m=\u001b[39m _check_unknown(values, uniques)\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m diff:\n\u001b[1;32m--> 232\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(diff)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msearchsorted(uniques, values)\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: [2.0]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Cargar el modelo entrenado\n",
    "model = PredictorModel(input_size, hidden_size, output_size)\n",
    "model.load_state_dict(torch.load(\"modelo_entrenado2.pth\"))  # Asegúrate de reemplazar \"ruta_del_modelo_entrenado.pth\" con la ruta real\n",
    "\n",
    "# Leer el archivo CSV con los partidos\n",
    "partidos_df = pd.read_csv(\"Eliminatoria actual/cuartos.csv\")  # Asegúrate de reemplazar \"ruta_del_archivo_csv.csv\" con la ruta real\n",
    "# Convertir la columna \"fase\" a minúsculas y capitalizar la primera letra\n",
    "partidos_df['fase'] = partidos_df['fase'].str.lower().str.capitalize()\n",
    "\n",
    "# Crea un diccionario para mapear las etapas a valores numéricos\n",
    "etapas_dict = {'Grupos': 0, 'Octavos': 1, 'Cuartos': 2, 'Semis': 3, 'Final': 4}\n",
    "\n",
    "# Reemplaza las etiquetas de las etapas con valores numéricos\n",
    "partidos_df['fase'] = partidos_df['fase'].map(etapas_dict)\n",
    "\n",
    "# Crear un DataFrame para almacenar las predicciones completas de goles\n",
    "predicciones_df = pd.DataFrame(columns=[\"fase\", \"equipo_local\", \"goles_equipo_local\", \"equipo_visitante\", \"goles_equipo_visitante\"])\n",
    "\n",
    "# Iterar sobre cada fila del DataFrame de partidos\n",
    "for index, row in partidos_df.iterrows():\n",
    "    # Obtener los datos de entrada para hacer la predicción\n",
    "    fase = label_encoder.transform([row[\"fase\"]])[0]  # Transformar la fase a su valor codificado\n",
    "    equipo_local = row[\"equipo_local\"]\n",
    "    equipo_visitante = row[\"equipo_visitante\"]\n",
    "    datos_prediccion = torch.tensor([[fase, equipo_local, equipo_visitante]], dtype=torch.float32)\n",
    "    \n",
    "    # Realizar la predicción utilizando el modelo\n",
    "    predicciones = model(datos_prediccion).detach().numpy().round().astype(int)\n",
    "    \n",
    "    # Crear un nuevo DataFrame con la predicción completa para este partido\n",
    "    nueva_fila = {\n",
    "        \"fase\": row[\"fase\"],\n",
    "        \"equipo_local\": row[\"equipo_local\"],\n",
    "        \"goles_equipo_local\": predicciones[0][0],\n",
    "        \"equipo_visitante\": row[\"equipo_visitante\"],\n",
    "        \"goles_equipo_visitante\": predicciones[0][1]\n",
    "    }\n",
    "    predicciones_df = predicciones_df.append(nueva_fila, ignore_index=True)\n",
    "\n",
    "\n",
    "# Guardar el DataFrame con las predicciones completas en un nuevo archivo CSV\n",
    "predicciones_df.to_csv(\"predicciones_completas.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
